{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c2e18c-5e2f-4439-9410-98defa92362c",
   "metadata": {},
   "source": [
    "# **NLP com Flair**\n",
    "Este tutorial é baseado no livro \"Natural Language Processing with Flair\".\n",
    "\n",
    "# 6 - Modelos de Classificação\n",
    "\n",
    "No notebook anterior treinamos um modelo de word embedding. O word embedding é útil em tarefas como NER e PoS, pois\n",
    "nosso objetivo é justamente taggear palavras (tokens). Isso não é o caso no problema de classificação.\n",
    "\n",
    "Por exemplo, suponho que temos um texto onde um juiz dá uma sentença. O objetivo é então criar um\n",
    "modelo que identifica se a decisão foi favorável ou desfavorável. Esse tipo de coisa pode ser feita\n",
    "usando ferramentas como Regex. Porém, esse tipo método é menos robusto caso o texto não seja tão padronizado.\n",
    "No caso dos textos de sentenças, pode ser que o juiz sempre use algo como \"julgo a sentença procedente\". Porém, podem\n",
    "haver variações, como \"julgo a sentença à favor do réu\", ou alguma varição não prevista, até mesmo um erro ortográfico.\n",
    "\n",
    "A forma de lidar com esse tipo de problema envolve criar um embedding para a sentença/documento\n",
    "como um todo, e não para cada palavra. Assim, queremos avaliar se a sentença\n",
    "indica decisão positiva ou negativa.\n",
    "\n",
    "Já falamos brevemente de document embeddings no primeiro notebook.\n",
    "Um tipo bem simples é o chamado `DocumentPoolEmbeddings`, que nada mais é que uma média\n",
    "dos word embeddings.\n",
    "\n",
    "Outro é o `DocumentRNNEmbeddings`, que usa redes RNN. Porém, vamos focar no\n",
    "`TransformerDocumentEmbeddings`, pois estes são os que costumam apresentar melhor desempenho."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b75f40f-70ef-4d95-a308-ea214ccc3e73",
   "metadata": {},
   "source": [
    "## Importando TransformerDocumentEmbedding\n",
    "\n",
    "Utilizaremos o modelo e dados do [legalnlp](https://github.com/felipemaiapolo/legalnlp). Baixe os dados desse repositório, que se encontram em `demo/data_base.csv`.\n",
    "\n",
    "Vamos começar importando o embedding. Vamos usar o modelo BERTikal, que foi treinado em dados jurídicos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512e644f-7486-48b9-bd9b-cb9dd74ca8d1",
   "metadata": {},
   "source": [
    "Primeiro, rode o código abaixo caso não tenha os pacotes instalados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "449d468e-5467-4f54-b3f2-0c60dcba7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install legalnlp\n",
    "# !pip install transformers\n",
    "# !pip install flair\n",
    "# !pip install pandas\n",
    "# !pip install scikit-learn\n",
    "\n",
    "# from legalnlp.get_premodel import *\n",
    "\n",
    "# get_premodel('bert')\n",
    "# !mkdir models\n",
    "# !mv BERTikal ./models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c960ea5-da8b-4303-8f36-0f1623d92b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davibarreira/miniconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from legalnlp.clean_functions import *\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "document_embeddings = TransformerDocumentEmbeddings('./models/BERTikal/')\n",
    "\n",
    "\n",
    "# Precisamos ajustar esses parametros para evitar que o numero de tokens ultrapasse o limite\n",
    "document_embeddings.tokenizer.model_max_length = 512\n",
    "document_embeddings.truncate = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df1cefa-f1bb-4299-8e63-d0e2f6999846",
   "metadata": {},
   "source": [
    "## GPU ou CPU?\n",
    "\n",
    "Se tiver uma GPU, basta não roda o código abaixo, pois ele irá mudar para rodar na cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d82d6165-1c86-42d4-b18a-c08bc532c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import flair, torch\n",
    "# flair.device = torch.device('cpu') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449eedc0-ae8c-4156-a0b8-c28fdbdb75ee",
   "metadata": {},
   "source": [
    "## Criando Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1faf3e53-4f6c-433e-8b6d-8261133338e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('./data/data_base.csv')\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df = shuffle(df, random_state=7).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63eb61ed-5f08-400f-b776-779f4d8cd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val   = int(int(df.shape[0]*0.7)* 0.1)\n",
    "n_train = int(df.shape[0]*0.7-n_val)\n",
    "n_test  = df.shape[0] - n_val - n_train\n",
    "\n",
    "train = df.iloc[0:n_train].copy()\n",
    "dev   = df.iloc[n_train: n_train + n_val].copy()\n",
    "test  = df.iloc[n_train + n_val:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85850f26-742d-4cc8-8583-35f3ad27ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('./data/train.csv',index=False, sep='\\t')\n",
    "test.to_csv('./data/test.csv',index=False, sep='\\t')\n",
    "dev.to_csv('./data/dev.csv',index=False, sep='\\t')\n",
    "\n",
    "# Funcoes do legalnlp que limpa o texto\n",
    "train['text'] = train.text.apply(clean_bert)\n",
    "test['text'] = test.text.apply(clean_bert)\n",
    "dev['text'] = dev.text.apply(clean_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44e0f578-1cb2-4eea-9bf4-adbb2b7555ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-21 18:28:27,887 Reading data from data\n",
      "2022-10-21 18:28:27,888 Train: data/train.csv\n",
      "2022-10-21 18:28:27,889 Dev: data/dev.csv\n",
      "2022-10-21 18:28:27,890 Test: data/test.csv\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = './data'\n",
    "\n",
    "# column format indicating which columns hold the text and label(s)\n",
    "columns = {0: 'text', 1: 'label'}\n",
    "\n",
    "# load corpus containing training, test and dev data and if CSV has a header, you can skip it\n",
    "\n",
    "lbl_type = 'label'\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
    "                                         columns,\n",
    "                                         skip_header=True,\n",
    "                                         delimiter='\\t',\n",
    "                                         label_type=lbl_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed291105-0fd3-43cd-87f3-51684fbe99f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-21 18:28:28,718 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4063it [00:01, 3940.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-21 18:28:29,757 Dictionary created for label 'label' with 4 values: H:Arquivado (seen 1905 times), H:Ativo (seen 1844 times), H:Suspenso (seen 314 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_dict = corpus.make_label_dictionary(label_type=lbl_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd1b49a9-879e-436b-a15f-5e51f7f9d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "\n",
    "classifier = TextClassifier(document_embeddings,\n",
    "                            label_dictionary=label_dict,\n",
    "                            label_type=lbl_type)\n",
    "\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "trainer.fine_tune('classifier',\n",
    "              learning_rate = 5e-05,\n",
    "              mini_batch_size = 32,\n",
    "              max_epochs = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802b346-a13b-456d-a0e5-5f8e78583f15",
   "metadata": {},
   "source": [
    "## Fazendo Previsões\n",
    "\n",
    "Depois do modelo treinado, podemos usar o modelo para fazer previsões. Note que no Flair, a previsão\n",
    "fica atrelada à sua sentença. Veja abaixo como usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ab573-7e6f-40eb-918f-3ae717309fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = TextClassifier.load('classifier/final-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d47c27-b7a1-4632-ac57-1dd48091b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = Sentence(df.text.iloc[-1])\n",
    "classifier.predict(pred)\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
