{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15faa928-92e6-417d-bb07-33de86033d5b",
   "metadata": {},
   "source": [
    "# **NLP com Flair**\n",
    "Este tutorial é baseado no livro \"Natural Language Processing with Flair\".\n",
    "\n",
    "# 2 - Sequence Tagging\n",
    "\n",
    "Sequence tagging é a tarefa que envolve \"taggear\" tokens ou outras unidades de texto. Um exemplo simples\n",
    "é por exemplo identificar as tokens que são verbos. Um tipo de sequence tagging é o chamado\n",
    "Named Entity Recognition (NER), que consiste em identificar entidades como organizações, lugares, e pessoas.\n",
    "Outro exemplo famoso é o que se chama de Part-of-Speech (PoS), que é a tarefa de identificar morfologicamente as tokens (e.g. substantivos, adjetivos, verbos...).\n",
    "\n",
    "## NER\n",
    "Vamos iniciar falando um pouco sobre NER.\n",
    "Infelizmente, o Flair não possui modelos pré-treinados em português. Então vamos usar texto em inglês para\n",
    "apresentar as funcionalidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b2392d-88bf-4f5b-a053-75f129dd03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davibarreira/miniconda3/envs/nlp/lib/python3.9/site-packages/huggingface_hub/file_download.py:588: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-18 18:12:58,485 loading file /home/davibarreira/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
      "2022-10-18 18:13:00,672 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "Sentence: \"Berlin\" → [\"Berlin\"/LOC]\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "tagger = SequenceTagger.load('ner')\n",
    "sentence = Sentence('Berlin')\n",
    "tagger.predict(sentence)\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5866b7-0d37-4907-994c-01f0874e48c9",
   "metadata": {},
   "source": [
    "Como o Flair não possui modelos em português para o que queremos, vamos importar um modelo pré-treinado do Hugging Face. \n",
    "Esse modelo é um transformer treinando em textos jurídicos em português."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32717ab-e04d-4ca5-a767-b419046a1408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"pierreguillou/ner-bert-large-cased-pt-lenerbr\")\n",
    "\n",
    "# # model = AutoModelForTokenClassification.from_pretrained(\"pierreguillou/ner-bert-large-cased-pt-lenerbr\")\n",
    "# tagger = SequenceTagger.load(\"../../ner-bert-large-cased-pt-lenerbr/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4456f3f-ef35-4a53-b2a4-f87a95ca3cd7",
   "metadata": {},
   "source": [
    "## Part-of-Speech\n",
    "\n",
    "This has the same interface, we only need to alter our tagger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0478c95c-c3bb-4462-abcd-fd50a6dccabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davibarreira/miniconda3/envs/nlp/lib/python3.9/site-packages/huggingface_hub/file_download.py:588: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-18 18:32:33,239 loading file /home/davibarreira/.flair/models/pos-english/a9a73f6cd878edce8a0fa518db76f441f1cc49c2525b2b4557af278ec2f0659e.121306ea62993d04cd1978398b68396931a39eb47754c8a06a87f325ea70ac63\n",
      "2022-10-18 18:32:33,466 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n",
      "Sentence: \"Making a living\" → [\"Making\"/VBG, \"a\"/DT, \"living\"/NN]\n"
     ]
    }
   ],
   "source": [
    "tagger = SequenceTagger.load('pos')\n",
    "sentence = Sentence('Making a living')\n",
    "tagger.predict(sentence)\n",
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078044d-20cd-42fb-a35a-f042c24b41d5",
   "metadata": {},
   "source": [
    "## Avaliando as previsões\n",
    "\n",
    "Para avaliar o quão preciso nosso tagger é, podemos usar métricas como acurácia (acertos / total). Porém, essa\n",
    "métrica pode ser ruim caso nosso dataset seja desbalanceado em relação à distribuição das tags. Por exemplo,\n",
    "se 80% das tags são \"x\", então um modelo que sempre prevê \"x\" irá acertar 80% das vezes.\n",
    "\n",
    "Uma métrica mais interessante é o F1. Essa métrica faz uma média espectral da medida de precisão e revocação (*recall*).\n",
    "Lembre:\n",
    "\n",
    "$$\n",
    "\\text{precisao}_i := \\frac{tp_i}{tp_i+fp_i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{recall}_i := \\frac{tp_i}{tp_i+fn_i}\n",
    "$$\n",
    "\n",
    "Considere que temos $n$ tags possíveis. O $tp_i$ é o *true positive* para a tag $i$, i.e. a quantidade de vezes que \n",
    "acertamos prevendo a tag $i$. O $fp_i$ é a quantidade de \"falso positivo\" para tag $i$ e $fn_i$ a quantidade de \"falso negativo\",\n",
    "ou seja, uma palavra tinha a tag $i$, mas nosso modelo não classificou com a tag $i$.\n",
    "Note que a precisão e o recall são calculados para cada tag $i$ separadamente.\n",
    "\n",
    "O score F1 é então:\n",
    "\n",
    "$$\n",
    "F1_i := 2 \\cdot \\frac{\\text{precisao}_i \\cdot \\text{recall}_i}{\\text{precisao}_i + \\text{recall}_i}\n",
    "$$\n",
    "\n",
    "Temos então uma medida F1 para cada tag do nosso modelo. Se quisermos avaliar o desempenho considerando a previsão\n",
    "de todas as tags, podemos utilizar tanto o que se chama de *macro* F1, como *micro* F1.\n",
    "\n",
    "O macro F1 é a média dos F1s, e o micro é a soma dos $tp$, $fp$ e $fn$.\n",
    "Ou seja, o F1 macro é:\n",
    "\n",
    "$$\n",
    "\\text{macro F1}:= \\frac{\\sum_i^n \\text{F1}_i}{n}\n",
    "$$\n",
    "\n",
    "E para o micro temos:\n",
    "\n",
    "$$\n",
    "\\text{Pr}:= \\frac{\\left(\\sum_i^n tp_i \\right)}{\\left(\\sum_i^n tp_i \\right) + \\left(\\sum_i^n fp_i \\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Re}:= \\frac{\\left(\\sum_i^n tp_i \\right)}{\\left(\\sum_i^n tp_i \\right) + \\left(\\sum_i^n fn_i \\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{micro F1} := 2 \\cdot \\frac{Pr \\cdot Re}{Pr + Re}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47386982-5838-465b-a787-1a0bb7c2604d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
